{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicit Alternative Least Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "In the last section, we have used KNN to created the first restaurant recommendation model. In this section I will be using ALS to solve the exact same probelm; and let see if there is any difference between this two methodologies.\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of ALS that are commonly used:\n",
    " * Explicit ALS\n",
    " * Implicit ALS\n",
    "\n",
    "The only difference them is that in Explicit ALS, we have observation on users rating, which is the case for this dataset. But for the case of Implicit ALS, we have to define users rating based on user behaviors, for example, clickdata, time spent on the webpage, and etc.\n",
    "\n",
    "In this section, I will be focusing on the **Explicit ALS**.\n",
    "\n",
    "--------------------------\n",
    "\n",
    "To use Apache Spark, I spent some time to figure out on to set up Spark environment on my local machine. The tutorial I used can be found in [here](https://medium.com/@GalarnykMichael/install-spark-on-windows-pyspark-4498a5d8d66c)\n",
    "\n",
    "\n",
    "Now let's start. First, let's import the libraries,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row\n",
    "import time\n",
    "import os\n",
    "os.chdir(\"D:\\\\Yelp data\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Spark session and import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+------------+------------+-----------+----------+--------------------+-------+--------------------+-----------+------------------+--------------+-----------------+-----------+----------+---------+----+\n",
      "|_c0|           review_id|             user_id|         business_id|stars_review|useful_final|funny_final|cool_final|          categories|   city|                name|postal_code|review_count_final|stars_business|review_count_user|useful_user|funny_user|cool_user|fans|\n",
      "+---+--------------------+--------------------+--------------------+------------+------------+-----------+----------+--------------------+-------+--------------------+-----------+------------------+--------------+-----------------+-----------+----------+---------+----+\n",
      "|  6|ymAUG8DZfQcFTBSOi...|u0LXt3Uea_GidxRW1...|9_CGhHMz8698M9-Pk...|           4|           0|          0|         2|Restaurants, Viet...|Toronto|Little Coxwell Vi...|    M4C 3G5|               115|           4.0|              359|         79|         7|       22|   8|\n",
      "|  7|8UIishPUD92hXtScS...|u0LXt3Uea_GidxRW1...|gkCorLgPyQLsptTHa...|           4|           1|          0|         0|Food, Restaurants...|Toronto|  Broadview Espresso|    M4K 2P9|                65|           4.0|              359|         79|         7|       22|   8|\n",
      "|  8|w41ZS9shepfO3uEyh...|u0LXt3Uea_GidxRW1...|5r6-G9C4YLbC7Ziz5...|           3|           1|          0|         0|Restaurants, Pout...|Toronto|Poutini's House o...|    M6J 1H9|               268|           3.5|              359|         79|         7|       22|   8|\n",
      "| 10|PIsUSmvaUWB00qv5K...|u0LXt3Uea_GidxRW1...|z8oIoCT1cXz7gZP5G...|           4|           1|          0|         0|Canadian (New), B...|Toronto|Milliken Bar & Re...|    M1S 3T6|                36|           3.5|              359|         79|         7|       22|   8|\n",
      "| 11|PdZ_uFjbbkjtm3SCY...|u0LXt3Uea_GidxRW1...|XWTPNfskXoUL-Lf32...|           3|           5|          0|         1|Restaurants, Dine...|Toronto|      Rosedale Diner|    M4W 2L9|                80|           3.5|              359|         79|         7|       22|   8|\n",
      "| 13|lsoSqIrrDbQvWpMvs...|u0LXt3Uea_GidxRW1...|RtUvSWO_UZ8V3Wpj0...|           3|           2|          1|         1|Bars, Restaurants...|Toronto|KINKA IZAKAYA ORI...|    M5B 2A2|              1397|           4.0|              359|         79|         7|       22|   8|\n",
      "| 14|23eqwlZzCWZkADWfd...|u0LXt3Uea_GidxRW1...|Aov96CM4FZAXeZvKt...|           5|           2|          0|         1|Specialty Food, E...|Toronto| Que Ling Restaurant|    M4M 2K1|                61|           4.0|              359|         79|         7|       22|   8|\n",
      "| 17|xdu8nXrbNKeaywCX7...|u0LXt3Uea_GidxRW1...|PFPUMF38-lraKzLcT...|           3|           2|          0|         0|American (Traditi...|Toronto|  Mitzi's On College|    M6H 1A3|                34|           3.5|              359|         79|         7|       22|   8|\n",
      "| 18|K7o5jDInfmX3cY5oH...|u0LXt3Uea_GidxRW1...|oWTn2IzrprsRkPfUL...|           3|           4|          0|         0|Restaurants, Burgers|Toronto| The Burger's Priest|    M4L 1G3|               435|           3.5|              359|         79|         7|       22|   8|\n",
      "| 19|WYDFJOBOl7cycd7gN...|u0LXt3Uea_GidxRW1...|zgQHtqX0gqMw1nlBZ...|           1|           9|          2|         1|Ramen, Soup, Kore...|Toronto| Momofuku Noodle Bar|    M5H 0A3|               897|           3.0|              359|         79|         7|       22|   8|\n",
      "+---+--------------------+--------------------+--------------------+------------+------------+-----------+----------+--------------------+-------+--------------------+-----------+------------------+--------------+-----------------+-----------+----------+---------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"movie recommendation\") \\\n",
    "        .getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "sc.setCheckpointDir('C:\\\\Users\\\\qwerdf\\\\Desktop\\\\Coding\\\\pyspark')\n",
    "#Add checkpoint becasue it is HDFS at a local machine; memory can be a contrainst in this case.\n",
    "\n",
    "joint_table=spark.read.load(\"yelp_train.csv\",format='csv',header=True)\n",
    "joint_table.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will need to convert **business_id** and **user_id** into a integer unique identifer, because this is what spark.ALS would take. \n",
    "\n",
    "---\n",
    "\n",
    "Here I leverage the rank over combination in SQL to assign a unique identifier for each user and business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------+--------------------+\n",
      "|business_id_int|user_id_int|stars_review_int|                name|\n",
      "+---------------+-----------+----------------+--------------------+\n",
      "|         130673|          1|               1|Posticino Ristorante|\n",
      "|          91180|          2|               4|        The Pie Guyz|\n",
      "|         345830|          3|               2| Slumdog Bar & Grill|\n",
      "|         137697|          4|               2|                Cava|\n",
      "|         128641|          5|               3|      Sansotei Ramen|\n",
      "|         132919|          5|               4|CoCo Fresh Tea & ...|\n",
      "|         178897|          5|               5|    Wooffles & Cream|\n",
      "|         438575|          5|               2|          Little Fin|\n",
      "|           5406|          9|               1|The Works Gourmet...|\n",
      "|          25789|          9|               5|          Cafe Jules|\n",
      "+---------------+-----------+----------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ALS_data=joint_table.withColumn(\"business_id_int\",rank().over(Window.orderBy(asc(\"business_id\")))) \\\n",
    "                    .withColumn(\"user_id_int\",rank().over(Window.orderBy(asc(\"user_id\")))) \\\n",
    "                    .withColumn(\"stars_review_int\",joint_table[\"stars_review\"].cast(IntegerType())) \\\n",
    "                    .select([\"business_id_int\",\"user_id_int\",\"stars_review_int\",\"name\"]).cache()\n",
    "\n",
    "ALS_data.createOrReplaceTempView(\"ALS_data\")\n",
    "ALS_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that every line has **business_id**, **review score** and **user id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------+-----------+----------------+----+\n",
      "|business_id|business_id_int|user_id|user_id_int|stars_review_int|name|\n",
      "+-----------+---------------+-------+-----------+----------------+----+\n",
      "+-----------+---------------+-------+-----------+----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train,validation=ALS_data.randomSplit([0.8,0.2],seed=1992)\n",
    "train.createOrReplaceTempView(\"train\")\n",
    "spark.sql(\n",
    "    \"Select * \\\n",
    "     FROM  train \\\n",
    "     WHERE stars_review_int is null or business_id_int is null or user_id_int is null\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function for ALS parameter tuning. The two parameter needs to be tuned are $ lambda $, which is the regularization parameter that prevent the model from overfitting; and the $ rank $, which defines the complexity of the model.\n",
    "\n",
    "Root mean square error is the error function used for ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALS_parameter_tuning(train_data,validation_data,maxiter,reg_param,rank):\n",
    "        min_error=float('inf')\n",
    "        best_rank=-1\n",
    "        best_regularization=0,\n",
    "        best_model=None\n",
    "        run_time=time.time()\n",
    "        for rank_iter in ranks:\n",
    "            for reg in reg_param:\n",
    "                start_time=time.time()\n",
    "                als=ALS(\n",
    "                        maxIter=maxiter,\n",
    "                        regParam=reg,\n",
    "                        userCol=\"user_id_int\",\n",
    "                        itemCol=\"business_id_int\",\n",
    "                        ratingCol=\"stars_review_int\",\n",
    "                        rank=rank_iter,\n",
    "                        coldStartStrategy=\"drop\",\n",
    "                        checkpointInterval=2\n",
    "                        )\n",
    "                model=als.fit(train_data)\n",
    "                predictions=model.transform(validation_data)\n",
    "                #use rmse to calculate the error term for each model; The smaller the better.\n",
    "                evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"stars_review_int\",\n",
    "                                              predictionCol=\"prediction\")\n",
    "                rmse=evaluator.evaluate(predictions)\n",
    "                print(\"With reg Param={} and rank={}, RMSE of ALS is {}\".format(reg,rank_iter,rmse))\n",
    "        if rmse<=min_error:\n",
    "            min_error=rmse\n",
    "            best_rank=rank_iter\n",
    "            best_regularization=reg\n",
    "            best_model=model\n",
    "        run_time=time.time()-run_time\n",
    "        return best_rank,best_regularization,best_model,run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxiter=10\n",
    "ranks=range(10,21,2)\n",
    "start_time = time.time()\n",
    "reg_params=[0.02,0.05,0.1,0.2,0.3,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With reg Param=0.02 and rank=10, RMSE of ALS is 1.7949761352739237\n",
      "With reg Param=0.05 and rank=10, RMSE of ALS is 1.5408083354043882\n",
      "With reg Param=0.1 and rank=10, RMSE of ALS is 1.3971850282005798\n",
      "With reg Param=0.2 and rank=10, RMSE of ALS is 1.2986664217191408\n",
      "With reg Param=0.3 and rank=10, RMSE of ALS is 1.2706742549255283\n",
      "With reg Param=0.5 and rank=10, RMSE of ALS is 1.2871139932253073\n",
      "With reg Param=0.02 and rank=12, RMSE of ALS is 1.8167712994440626\n",
      "With reg Param=0.05 and rank=12, RMSE of ALS is 1.5469455633972993\n",
      "With reg Param=0.1 and rank=12, RMSE of ALS is 1.4013181306592983\n",
      "With reg Param=0.2 and rank=12, RMSE of ALS is 1.3018688871840587\n",
      "With reg Param=0.3 and rank=12, RMSE of ALS is 1.2725680032318314\n",
      "With reg Param=0.5 and rank=12, RMSE of ALS is 1.2878969365715573\n",
      "With reg Param=0.02 and rank=14, RMSE of ALS is 1.7851608968941934\n",
      "With reg Param=0.05 and rank=14, RMSE of ALS is 1.5342439796362384\n",
      "With reg Param=0.1 and rank=14, RMSE of ALS is 1.3946430205670426\n",
      "With reg Param=0.2 and rank=14, RMSE of ALS is 1.2974107282946672\n",
      "With reg Param=0.3 and rank=14, RMSE of ALS is 1.2702195909163392\n",
      "With reg Param=0.5 and rank=14, RMSE of ALS is 1.2873111115002522\n",
      "With reg Param=0.02 and rank=16, RMSE of ALS is 1.7719774130583599\n",
      "With reg Param=0.05 and rank=16, RMSE of ALS is 1.5262633989994943\n",
      "With reg Param=0.1 and rank=16, RMSE of ALS is 1.3893043852695566\n",
      "With reg Param=0.2 and rank=16, RMSE of ALS is 1.2963737845381906\n",
      "With reg Param=0.3 and rank=16, RMSE of ALS is 1.2705995226131432\n",
      "With reg Param=0.5 and rank=16, RMSE of ALS is 1.2882012604546047\n",
      "With reg Param=0.02 and rank=18, RMSE of ALS is 1.7482427717474638\n",
      "With reg Param=0.05 and rank=18, RMSE of ALS is 1.514035655054001\n",
      "With reg Param=0.1 and rank=18, RMSE of ALS is 1.386999223242557\n",
      "With reg Param=0.2 and rank=18, RMSE of ALS is 1.2971283476899829\n",
      "With reg Param=0.3 and rank=18, RMSE of ALS is 1.2711827603759696\n",
      "With reg Param=0.5 and rank=18, RMSE of ALS is 1.2880800185429429\n",
      "With reg Param=0.02 and rank=20, RMSE of ALS is 1.7296673746458489\n",
      "With reg Param=0.05 and rank=20, RMSE of ALS is 1.5038774315594747\n",
      "With reg Param=0.1 and rank=20, RMSE of ALS is 1.3828684095504769\n",
      "With reg Param=0.2 and rank=20, RMSE of ALS is 1.2952708394830361\n",
      "With reg Param=0.3 and rank=20, RMSE of ALS is 1.2698801287252734\n",
      "With reg Param=0.5 and rank=20, RMSE of ALS is 1.2874018759308063\n"
     ]
    }
   ],
   "source": [
    "best_rank,best_regularization,best_model,run_time=ALS_parameter_tuning(train_data=train,validation_data=validation,maxiter=maxiter,reg_param=reg_params,rank=ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result, we can see that when $ Lambda $ =0.3 and rank=20, ALS gives the best RMSE at 1.27\n",
    "\n",
    "What we can observe is that RMSE is montonic with regard to rank. The higher the rank the lower the RMSE; that makes perfect as the more complex the model is, the more accurate it would be. However, we observe there is a local minimum for RMSE when **lambda** is changed. This is becasue **lambda** is the regularization factor for overfitting the model. The higher the **lambda** is, the more penalty it would put on the model for overfitting. In this case, the model performs worse when **lambda = 0.5** than when **lambda=0.3** becasue the model lost too much detail in describing the data to prevent it from overfitting.\n",
    "\n",
    "----------------------\n",
    "Now, we have the best model, let's use ALS to make some recommendations. First, I will need a map to convert restaurant name into the integer business id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_restaurant_id(data,restaurant_list):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    final_list=[]\n",
    "    if restaurant_list is None:\n",
    "        return final_list\n",
    "    for restaurant in restaurant_list:\n",
    "        restaurant_id=data.where(col('name') \\\n",
    "                          .like(restaurant)) \\\n",
    "                          .select('business_id_int') \\\n",
    "                          .distinct() \\\n",
    "                          .rdd \\\n",
    "                          .map(lambda r:r[0]) \\\n",
    "                          .collect()    \n",
    "                          \n",
    "        final_list.extend(restaurant_id)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the function that would add new data into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_user_data(train_data,my_fav,my_least_fav=None):\n",
    "    \"\"\"\n",
    "    function to add new user's data into train model\n",
    "    \n",
    "    \n",
    "    --------------\n",
    "    \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    train_data: spark dataframe, Initial data for user_id,business_id,rating combinations\n",
    "    \n",
    "    my_fav: list of strings, favourite restaurant list; Assume these restaurants are marked as 5\n",
    "    \n",
    "    my_least_fav: list of strings, least favourite restaurant list; Assume these restaurants are makred as 1\n",
    "    \"\"\"\n",
    "    new_user_id=train_data.rdd.map(lambda r:r[1]).max()+1\n",
    "    columns=['business_id_int','user_id_int','stars_review','name']\n",
    "    print(\"initialize data for new userid {}\".format(new_user_id))\n",
    "    fav_list=find_restaurant_id(train_data,my_fav)\n",
    "    fav_rows=[(restaurant_id,new_user_id,5,restaurant) for restaurant_id,restaurant in zip(fav_list,my_fav)]\n",
    "    fav_df=spark.createDataFrame(fav_rows,columns)\n",
    "    final_set=train_data.union(fav_df)\n",
    "    if my_least_fav is not None:\n",
    "        least_fav_list=find_restaurant_id(train_data,my_least_fav)\n",
    "        least_fav_rows=[(restaurant_id,new_user_id,1,restaurant) for restaurant_id,restaurant in zip(least_fav_list,my_least_fav)]\n",
    "        least_fav_df=spark.createDataFrame(least_fav_rows,columns)\n",
    "        final_set=train_data.union(least_fav_df)\n",
    "    return new_user_id,final_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_personal_recommendation_als(train_data,my_fav,my_least_fav=None,reg_param=0.3,rank=20,maxiter=10):\n",
    "    \"\"\"\n",
    "    function to give personal recommendations to the defined user who has record of favourite restaurant and least favourite restaurant\n",
    "    \n",
    "    -----------\n",
    "    parameters:\n",
    "    \n",
    "    train_data: spark dataframe, Initial data for user_id,business_id,rating combinations\n",
    "    \n",
    "    my_fav: list of strings, favourite restaurant list; Assume these restaurants are marked as 5\n",
    "    \n",
    "    my_least_fav: list of strings, least favourite restaurant list; Assume these restaurants are makred as 1\n",
    "    \n",
    "    reg_param: lambda in ALS, defined the overfitting penalty of the ALS\n",
    "    \n",
    "    rank: rank of ALS, defined the complexity of ALS\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    best_regularization=reg_param\n",
    "    best_rank=rank\n",
    "    new_user_id,new_set=add_new_user_data(train_data,my_fav,my_least_fav)\n",
    "    \n",
    "    best_als=ALS(maxIter=maxiter, \\\n",
    "             regParam=best_regularization, \\\n",
    "             userCol=\"user_id_int\", \\\n",
    "             itemCol=\"business_id_int\", \\\n",
    "             ratingCol=\"stars_review_int\", \\\n",
    "             rank=best_rank, \\\n",
    "             coldStartStrategy=\"drop\", \\\n",
    "             checkpointInterval=2\n",
    "             )\n",
    "    model=best_als.fit(new_set)\n",
    "    users=new_set.select(best_als.getUserCol()).where(col('user_id_int')==new_user_id)\n",
    "    userSubsetRecs=model.recommendForUserSubset(users,10)\n",
    "    print(\"Here are the top 10 recommandations for you given your favourite and least favourite food\")\n",
    "    for restaurant in userSubsetRecs.select(\"recommendations\").collect()[0][0]:\n",
    "        restaurant_id=restaurant.__getattr__(\"business_id_int\")\n",
    "        restaurant_name=train_data.where(col('business_id_int')==restaurant_id).select('name').distinct().collect()\n",
    "        print(restaurant_name[0].__getattr__(\"name\"))\n",
    "    return userSubsetRecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize data for new userid 458670\n",
      "Here are the top 10 recommandations for you given your favourite and least favourite food\n",
      "Sushi Making For the Soul\n",
      "Shawarma Q\n",
      "Souppe Shoppe\n",
      "Sakura Ichiban Sushi Express\n",
      "Ten Ten Dim Sum\n",
      "Charlotte's Homemade Goodies\n",
      "Brando's Fried Chicken\n",
      "Lox + Schmear\n",
      "Pita Pit\n",
      "Touch Down Foods\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id_int: int, recommendations: array<struct<business_id_int:int,rating:float>>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_fav=['Emerald Chinese Restaurant']\n",
    "\n",
    "find_personal_recommendation_als(ALS_data,my_fav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the result from KNN\n",
    "\n",
    "-------------\n",
    "(KNN recommendation)\n",
    "\n",
    "Recommendations for Emerald Chinese Restaurant:\n",
    "\n",
    "1: Kobe Sushi, with distance of 0.8729435047925027\n",
    "\n",
    "2: Wonton Chai Noodle, with distance of 0.8717288246806103\n",
    "\n",
    "3: Chako, with distance of 0.8693951111786435\n",
    "\n",
    "4: Congee Dynasty, with distance of 0.8658084838350306\n",
    "\n",
    "5: Dynasty BBQ, with distance of 0.861539455352046\n",
    "\n",
    "6: McDonald's, with distance of 0.8548495321630935\n",
    "\n",
    "7: Wild Wing, with distance of 0.854550339648705\n",
    "\n",
    "8: Blue Lagoon Seafood Master, with distance of 0.8544684454549096\n",
    "\n",
    "9: Viet Thai Restaurant, with distance of 0.8378466819037798\n",
    "\n",
    "10: Happy Jade Seafood Chinese Restaurant, with distance of 0.7963704755081871\n",
    "\n",
    "-------------\n",
    "\n",
    "It is surprise to see that ALS gives totally different recommendations comparing to KNN. \n",
    "\n",
    "Let's take another example of J's Fish and Chips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize data for new userid 458670\n",
      "Here are the top 10 recommandations for you given your favourite and least favourite food\n",
      "Sushi Making For the Soul\n",
      "Souppe Shoppe\n",
      "Shawarma Q\n",
      "Ten Ten Dim Sum\n",
      "Charlotte's Homemade Goodies\n",
      "Sakura Ichiban Sushi Express\n",
      "Brando's Fried Chicken\n",
      "Lox + Schmear\n",
      "Pita Pit\n",
      "Cuisine of India\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id_int: int, recommendations: array<struct<business_id_int:int,rating:float>>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_fav=[\"Ann's Congee\"]\n",
    "find_personal_recommendation_als(ALS_data,my_fav,my_least_fav) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared it to the KNN model\n",
    "\n",
    "-------------------------------------------------------\n",
    "1: Taza Xpress, with distance of 0.9176311421402781\n",
    "\n",
    "2: Quesada Burritos and Tacos, with distance of 0.9038392772773323\n",
    "\n",
    "3: Twisted Fork, with distance of 0.896251268968906\n",
    "\n",
    "4: Yamato Sushi, with distance of 0.8955883310348774\n",
    "\n",
    "5: St. Louis Bar & Grill, with distance of 0.8916467512822909\n",
    "\n",
    "6: Otaru Sushi, with distance of 0.8879336370638948\n",
    "\n",
    "7: Bakery Garden, with distance of 0.8687116746261058\n",
    "\n",
    "8: Sunset Grill, with distance of 0.8267602678311907\n",
    "\n",
    "9: Mrs. Greek Souvlaki Express, with distance of 0.7920633893787208\n",
    "\n",
    "10: The Prince Albert Pub, with distance of 0.7846347538730261\n",
    "\n",
    "Again, very different."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
